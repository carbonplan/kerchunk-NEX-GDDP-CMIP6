{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison using kerchunk / datatree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coiled\n",
    "import dask\n",
    "import dask.bag as db\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from dask.distributed import wait\n",
    "from datatree import DataTree\n",
    "from utils import generate_WBGT, load_elev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = coiled.Cluster(\n",
    "    n_workers=10,\n",
    "    spot_policy=\"spot_with_fallback\",\n",
    "    arm=True,\n",
    ")\n",
    "client = cluster.get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the reference catalog into a Pandas DataFrame\n",
    "cat_df = pd.read_csv(\n",
    "    \"s3://carbonplan-share/nasa-nex-reference/reference_catalog_nested.csv\"\n",
    ")\n",
    "# Select only ssp245 && HISTORICAL!\n",
    "ssp245_historical_catalog = cat_df[cat_df[\"ID\"].str.contains(\"ssp245|historical\")]\n",
    "\n",
    "# Subset 20 GCMs for time comparison\n",
    "ssp245_historical_catalog = ssp245_historical_catalog.iloc[0:20]\n",
    "\n",
    "# Convert the DataFrame into a dictionary\n",
    "catalog = ssp245_historical_catalog.set_index(\"ID\").T.to_dict(\"records\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ref_ds(gcm_scenario: str, url: str):\n",
    "    storage_options = {\n",
    "        \"remote_protocol\": \"s3\",\n",
    "        \"target_protocol\": \"s3\",\n",
    "        \"target_options\": {\"anon\": True},\n",
    "        \"lazy\": True,\n",
    "        \"skip_instance_cache\": True,\n",
    "    }  # options passed to fsspec\n",
    "    open_dataset_options = {\"chunks\": {}}  # opens passed to xarray\n",
    "    ds = xr.open_dataset(\n",
    "        url,\n",
    "        engine=\"kerchunk\",\n",
    "        storage_options=storage_options,\n",
    "        open_dataset_options=open_dataset_options,\n",
    "    )\n",
    "\n",
    "    if {\n",
    "        \"huss\",\n",
    "        \"tasmax\",\n",
    "        \"tas\",\n",
    "    }.issubset(set(list(ds))):\n",
    "        ds = ds[[\"huss\", \"tasmax\", \"tas\"]]\n",
    "        # adding the gcm/scenario combo to attrs for later down the pipeline\n",
    "        ds.attrs[\"gcm_scenario\"] = gcm_scenario\n",
    "        return {gcm_scenario: ds}\n",
    "\n",
    "\n",
    "# convert catalog dict to tuples for dask bag starmap\n",
    "catalog_tuple_list = list(catalog.items())\n",
    "# Create a bag from tuple catalog\n",
    "cat_bag = db.from_sequence(catalog_tuple_list)\n",
    "# apply load_ref_ds to catalog tuple bag\n",
    "task_bag = filter(None, cat_bag.starmap(load_ref_ds).compute())\n",
    "\n",
    "# convert list of dicts to dict\n",
    "catalog_computed = {k: v for element in task_bag for k, v in element.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datatree object from computed dictionary\n",
    "dt = DataTree.from_dict(catalog_computed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def calc_wbgt(ds):\n",
    "    ds = ds.isel(time=slice(0, 365))\n",
    "    output = (\n",
    "        f\"s3://carbonplan-scratch/TEMP_NASA_NEX/wbgt-shade-\"\n",
    "        f\"gridded/years/{ds.attrs['gcm_scenario']}.zarr\"\n",
    "    )\n",
    "    return generate_WBGT(ds=ds, output_fpath=output, elev=elev)\n",
    "\n",
    "\n",
    "elev = load_elev()\n",
    "ds_list = [ds.to_dataset() for ds in dt.leaves if ds.dims]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute\n",
    "delayed_list = [calc_wbgt(ds) for ds in ds_list]\n",
    "wait(client.compute(delayed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
