{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison using open_mfdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import dask\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import thermofeel as tfcl\n",
    "import xarray as xr\n",
    "import xclim\n",
    "import s3fs\n",
    "from dask.distributed import Client\n",
    "import thermofeel as tf\n",
    "from utils import wbgt, load_elev, adjust_pressure\n",
    "\n",
    "gcm_list = [\n",
    "    \"ACCESS-CM2\",\n",
    "    \"ACCESS-ESM1-5\",\n",
    "    \"BCC-CSM2-MR\",\n",
    "    \"CanESM5\",\n",
    "    \"CMCC-CM2-SR5\",\n",
    "    \"CMCC-ESM2\",\n",
    "    \"CNRM-CM6-1\",\n",
    "    \"CNRM-ESM2-1\",\n",
    "    \"EC-Earth3-Veg-LR\",\n",
    "    \"EC-Earth3\",\n",
    "    \"FGOALS-g3\",\n",
    "    \"GFDL-CM4\",\n",
    "    \"GFDL-ESM4\",\n",
    "    \"GISS-E2-1-G\",\n",
    "    \"HadGEM3-GC31-LL\",\n",
    "    \"INM-CM4-8\",\n",
    "    \"INM-CM5-0\",\n",
    "    \"KACE-1-0-G\",\n",
    "    \"KIOST-ESM\",\n",
    "    \"MIROC-ES2L\",\n",
    "    \"MPI-ESM1-2-HR\",\n",
    "    \"MPI-ESM1-2-LR\",\n",
    "    \"MRI-ESM2-0\",\n",
    "    \"NorESM2-LM\",\n",
    "    \"NorESM2-MM\",\n",
    "    \"UKESM1-0-LL\",\n",
    "]\n",
    "\n",
    "gcms_with_nonstandard_calendars_list = [\n",
    "    \"BCC-CSM2-MR\",\n",
    "    \"CanESM5\",\n",
    "    \"CMCC-CM2-SR5\",\n",
    "    \"CMCC-ESM2\",\n",
    "    \"FGOALS-g3\",\n",
    "    \"GFDL-CM4\",\n",
    "    \"GFDL-ESM4\",\n",
    "    \"GISS-E2-1-G\",\n",
    "    \"HadGEM3-GC31-LL\",\n",
    "    \"INM-CM4-8\",\n",
    "    \"INM-CM5-0\",\n",
    "    \"KACE-1-0-G\",\n",
    "    \"KIOST-ESM\",\n",
    "    \"NorESM2-LM\",\n",
    "    \"NorESM2-MM\",\n",
    "    \"UKESM1-0-LL\",\n",
    "]\n",
    "\n",
    "os.environ[\"USE_PYGEOS\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coiled.list_instance_types(backend=\"aws\",arch=\"x86_64\", cores=2, memory=\"2 Gib\")\n",
    "import coiled\n",
    "\n",
    "cluster = coiled.Cluster(n_workers=10)\n",
    "client = cluster.get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading\n",
    "df = pd.read_csv(\n",
    "    \"s3://carbonplan-climate-impacts/extreme-heat/v1.0/inputs/nex-gddp-cmip6-files.csv\"\n",
    ")\n",
    "nasa_nex_runs_df = pd.DataFrame([run.split(\"/\") for run in df[\" fileURL\"].values]).drop(\n",
    "    [0, 1, 2, 3], axis=1\n",
    ")\n",
    "nasa_nex_runs_df.columns = [\n",
    "    \"GCM\",\n",
    "    \"scenario\",\n",
    "    \"ensemble_member\",\n",
    "    \"variable\",\n",
    "    \"file_name\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nasanex_filename(gcm, scenario):\n",
    "    \"\"\"\n",
    "    Load list of NASA-NEX files downloaded from their docs. We will use it to create\n",
    "    the catalog of available datasets. Largely this is used to filter out the GCMs\n",
    "    that don't have tasmax available.\n",
    "    \"\"\"\n",
    "    template_filename = nasa_nex_runs_df[\n",
    "        (nasa_nex_runs_df[\"GCM\"] == gcm)\n",
    "        & (nasa_nex_runs_df[\"scenario\"] == scenario)\n",
    "        & (nasa_nex_runs_df[\"variable\"] == \"tasmax\")\n",
    "    ][\"file_name\"].iloc[0]\n",
    "    (\n",
    "        _variable,\n",
    "        _timestep,\n",
    "        _gcm,\n",
    "        _scenario,\n",
    "        ensemble_member,\n",
    "        grid_code,\n",
    "        _yearnc,\n",
    "    ) = template_filename.split(\"_\")\n",
    "    return ensemble_member, grid_code\n",
    "\n",
    "\n",
    "##\n",
    "def load_nasanex(scenario, gcm, variables, years, chunk_dict=None):\n",
    "    \"\"\"\n",
    "    Read in NEX-GDDP-CMIP6 data from S3.\n",
    "    \"\"\"\n",
    "    fs = s3fs.S3FileSystem(anon=True, default_fill_cache=False)\n",
    "\n",
    "    file_objs = {}\n",
    "    ds = xr.Dataset()\n",
    "    ensemble_member, grid_code = find_nasanex_filename(gcm, scenario)\n",
    "    for i, var in enumerate(variables):\n",
    "        file_objs[var] = [\n",
    "            fs.open(\n",
    "                f\"nex-gddp-cmip6/NEX-GDDP-CMIP6/{gcm}/{scenario}/\"\n",
    "                f\"{ensemble_member}/{var}/{var}_day_{gcm}_{scenario}\"\n",
    "                f\"_{ensemble_member}_{grid_code}_{year}.nc\"\n",
    "            )\n",
    "            for year in years\n",
    "        ]\n",
    "        if i == 0:\n",
    "            ds[var] = xr.open_mfdataset(file_objs[var], engine=\"h5netcdf\")[var]\n",
    "        else:\n",
    "            new_var = xr.open_mfdataset(file_objs[var], engine=\"h5netcdf\")\n",
    "            new_var[\"time\"] = ds[variables[0]][\"time\"].values\n",
    "            ds[var] = new_var[var]\n",
    "    if chunk_dict is not None:\n",
    "        ds = ds.chunk(chunk_dict)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_years = {\"historical\": np.arange(1985, 1986), \"ssp245\": np.arange(2015, 2016)}\n",
    "# for timing we are grabbing a subset of 10 GCM's\n",
    "gcm_list = [\n",
    "    \"ACCESS-CM2\",\n",
    "    \"ACCESS-ESM1-5\",\n",
    "    \"BCC-CSM2-MR\",\n",
    "    \"CanESM5\",\n",
    "    \"CMCC-CM2-SR5\",\n",
    "    \"CMCC-ESM2\",\n",
    "    \"CNRM-CM6-1\",\n",
    "    \"CNRM-ESM2-1\",\n",
    "    \"EC-Earth3-Veg-LR\",\n",
    "    \"EC-Earth3\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elev = load_elev()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_wbgt_projections = True\n",
    "variables = [\"tasmax\", \"huss\", \"tas\"]\n",
    "if generate_wbgt_projections:\n",
    "    for gcm in gcm_list:\n",
    "        for scenario, years in scenario_years.items():\n",
    "            id_string = f\"{gcm}-{scenario}\"\n",
    "            print(id_string)\n",
    "            for year in years:\n",
    "                output = (\n",
    "                    f\"s3://carbonplan-scratch/TEMP_NASA_NEX/wbgt-shade-\"\n",
    "                    f\"gridded/years/{gcm}/{id_string}-{year}.zarr\"\n",
    "                )\n",
    "                ds = load_nasanex(\n",
    "                    gcm=gcm, scenario=scenario, variables=variables, years=[year]\n",
    "                )\n",
    "                ds = ds.isel(time=slice(0, 365))\n",
    "                # calculate elevation-adjusted pressure\n",
    "                ds[\"ps\"] = xr.apply_ufunc(\n",
    "                    adjust_pressure, ds[\"tas\"], elev, dask=\"allowed\"\n",
    "                ).rename({\"elevation\": \"ps\"})[\"ps\"]\n",
    "                ds[\"ps\"].attrs[\"units\"] = \"Pa\"\n",
    "                ds[\"hurs\"] = xclim.indices.relative_humidity(\n",
    "                    tas=ds[\"tasmax\"], huss=ds[\"huss\"], ps=ds[\"ps\"]\n",
    "                )\n",
    "                ds[\"tasmax\"].attrs = {}\n",
    "\n",
    "                # windspeed assumption of 0.5 m/s (approximating shaded/indoor\n",
    "                # conditions)\n",
    "                ds[\"sfcWind\"] = (ds[\"tas\"] - ds[\"tas\"]) + 0.5\n",
    "                ds[\"WBT\"] = tf.thermofeel.calculate_wbt(\n",
    "                    ds[\"tasmax\"] - 273.15, ds[\"hurs\"]\n",
    "                )\n",
    "\n",
    "                ds[\"BGT\"] = tf.thermofeel.calculate_bgt(\n",
    "                    ds[\"tasmax\"], ds[\"tasmax\"], ds[\"sfcWind\"]\n",
    "                )\n",
    "                ds[\"WBGT\"] = wbgt(ds[\"WBT\"], ds[\"BGT\"], ds[\"tasmax\"] - 273.15)\n",
    "                ds[\"WBGT\"].attrs[\"units\"] = \"degC\"\n",
    "                ds = ds[[\"WBGT\"]]\n",
    "                ds = dask.optimize(ds)[0]\n",
    "                t = ds.to_zarr(output, consolidated=True, mode=\"w\", compute=False)\n",
    "                t.compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
